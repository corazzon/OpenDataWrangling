{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주조 공정최적화 AI 데이터셋\n",
    "### 군집화와 차원축소\n",
    "https://www.kamp-ai.kr/aidataDetail?AI_SEARCH=%EC%A3%BC%EC%A1%B0+%EA%B3%B5%EC%A0%95%EC%B5%9C%EC%A0%81%ED%99%94+AI+%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%85%8B&page=1&DATASET_SEQ=53&DISPLAY_MODE_SEL=CARD&EQUIP_SEL=&GUBUN_SEL=&FILE_TYPE_SEL=&WDATE_SEL=\n",
    "\n",
    "출처 : 중소벤처기업부, Korea AI Manufacturing Platform(KAMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import koreanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 불러오기 (Unnamed: 0 컬럼을 인덱스로 지정)\n",
    "df = pd.read_csv('data/casting.csv', encoding='cp949', index_col='Unnamed: 0')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(10, 10), bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# 수치형 데이터만 추출 (이상치 및 무한대/NaN 값 제거)\n",
    "numeric_df = df.select_dtypes(include=['number']).replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# 모든 컬럼이 0이거나 상수인 경우 KMeans에서 오류 발생하므로, 분산이 0인 컬럼 제거\n",
    "numeric_df = numeric_df.loc[:, numeric_df.std() > 0]\n",
    "\n",
    "# 표준화\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(numeric_df)\n",
    "\n",
    "# KMeans 군집화 (5개 군집)\n",
    "# n_init 값을 명시적으로 지정 (sklearn 1.4 이상에서 경고 방지)\n",
    "kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "# 원본 데이터프레임에 군집 결과 추가\n",
    "df['cluster'] = -1\n",
    "df.loc[numeric_df.index, 'cluster'] = clusters\n",
    "\n",
    "# 각 군집별 데이터 개수 출력\n",
    "print(df['cluster'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "\n",
    "# sklearn의 RuntimeWarning 무시 (divide by zero, overflow 등)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "    # 실루엣 점수 계산\n",
    "    sil_score = silhouette_score(scaled_data, clusters)\n",
    "    print(f\"전체 실루엣 점수: {sil_score:.4f}\")\n",
    "\n",
    "    # 각 샘플별 실루엣 계수\n",
    "    sample_silhouette_values = silhouette_samples(scaled_data, clusters)\n",
    "\n",
    "n_clusters = 5\n",
    "fig, ax1 = plt.subplots(1, 1)\n",
    "fig.set_size_inches(8, 6)\n",
    "\n",
    "y_lower = 10\n",
    "for i in range(n_clusters):\n",
    "    ith_cluster_silhouette_values = sample_silhouette_values[clusters == i]\n",
    "    ith_cluster_silhouette_values = ith_cluster_silhouette_values[~np.isnan(ith_cluster_silhouette_values)]\n",
    "    ith_cluster_silhouette_values.sort()\n",
    "    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "    y_upper = y_lower + size_cluster_i\n",
    "\n",
    "    color = plt.cm.nipy_spectral(float(i) / n_clusters)\n",
    "    ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                      0, ith_cluster_silhouette_values,\n",
    "                      facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "    ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "    y_lower = y_upper + 10  # 10 for spacing between clusters\n",
    "\n",
    "ax1.set_title(\"군집별 실루엣 계수 시각화\")\n",
    "ax1.set_xlabel(\"실루엣 계수\")\n",
    "ax1.set_ylabel(\"샘플 인덱스\")\n",
    "\n",
    "ax1.axvline(x=sil_score, color=\"red\", linestyle=\"--\", label=\"전체 실루엣 점수\")\n",
    "ax1.set_yticks([])\n",
    "ax1.set_xlim([-0.1, 1])\n",
    "ax1.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# PCA 변환 전에 NaN, inf, -inf 값이 있으면 0으로 대체 (권장 방식)\n",
    "import numpy as np\n",
    "scaled_data_clean = np.nan_to_num(scaled_data, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# scaled_data를 2차원으로 차원 축소\n",
    "pca = PCA(n_components=2)\n",
    "data_2d = pca.fit_transform(scaled_data_clean)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(n_clusters):\n",
    "    plt.scatter(\n",
    "        data_2d[clusters == i, 0],\n",
    "        data_2d[clusters == i, 1],\n",
    "        label=f'Cluster {i}',\n",
    "        alpha=0.6\n",
    "    )\n",
    "plt.title('PCA 기반 2차원 군집 시각화')\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 군집 결과 해석을 위한 대표적인 분석 방법: 각 군집별 주요 변수의 평균/분포 비교, 군집별 특성 파악\n",
    "\n",
    "# 1. 군집별 주요 변수의 평균값 비교\n",
    "\n",
    "# clusters의 길이와 df의 길이가 다를 경우, clusters가 어떤 행에 해당하는지 인덱스를 명확히 지정해야 함\n",
    "import numpy as np\n",
    "\n",
    "# 매우 중요: 전처리된 데이터프레임의 인덱스를 'valid_idx'에 저장합니다.\n",
    "valid_idx = numeric_df.index\n",
    "\n",
    "# clusters가 numpy array 또는 pandas Series라고 가정\n",
    "if len(clusters) != len(df):\n",
    "    # scaled_data와 df의 인덱스가 다를 수 있으므로, scaled_data를 만든 원본 df의 인덱스를 추적해야 함\n",
    "    # scaled_data를 만들 때 사용한 인덱스가 valid_idx라면, 그 인덱스를 사용\n",
    "    # 예시: valid_idx = df.dropna(subset=사용한_컬럼들).index\n",
    "    # 아래는 일반적인 예시 코드 (valid_idx가 있다고 가정)\n",
    "    try:\n",
    "        valid_idx\n",
    "    except NameError:\n",
    "        raise ValueError(\n",
    "            \"clusters와 df의 길이가 다릅니다. \"\n",
    "            \"scaled_data를 만들 때 사용한 원본 df의 인덱스(valid_idx)를 지정해 주세요.\\n\"\n",
    "            \"예시: valid_idx = ...; clustered_df = df.loc[valid_idx].copy(); clustered_df['cluster'] = clusters\"\n",
    "        )\n",
    "    clustered_df = df.loc[valid_idx].copy()\n",
    "    clustered_df['cluster'] = clusters\n",
    "else:\n",
    "    clustered_df = df.copy()\n",
    "    clustered_df['cluster'] = clusters\n",
    "\n",
    "# 주요 수치형 변수만 추출 (예시: scaled_data의 컬럼명 사용)\n",
    "numeric_cols = clustered_df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# 군집별 평균값\n",
    "cluster_means = clustered_df.groupby('cluster')[numeric_cols].mean()\n",
    "print(\"군집별 주요 변수 평균값:\")\n",
    "from IPython.display import display  # display 함수가 없을 수 있으니 명시적으로 import\n",
    "display(cluster_means)\n",
    "\n",
    "# 2. 군집별 변수 분포 시각화 (박스플롯)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i, col in enumerate(numeric_cols[:5]):  # 주요 변수 5개만 예시로 시각화\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    sns.boxplot(x='cluster', y=col, data=clustered_df)\n",
    "    plt.title(col)\n",
    "    plt.xlabel('Cluster')\n",
    "    plt.tight_layout()\n",
    "plt.suptitle('군집별 주요 변수 분포 (일부 변수)')\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# 3. 군집별 샘플 수 확인\n",
    "print(\"군집별 샘플 수:\")\n",
    "print(clustered_df['cluster'].value_counts().sort_index())\n",
    "\n",
    "# 4. (선택) 군집별 범주형 변수 분포 확인\n",
    "cat_cols = clustered_df.select_dtypes(include=['object']).columns\n",
    "if len(cat_cols) > 0:\n",
    "    for col in cat_cols[:2]:  # 범주형 변수 2개만 예시\n",
    "        print(f\"\\n군집별 {col} 분포:\")\n",
    "        display(clustered_df.groupby('cluster')[col].value_counts(normalize=True).unstack().fillna(0))\n",
    "# 일반적으로 scaled_data를 만들 때 사용한 주요 수치형 컬럼에서 결측치가 없는 행을 사용합니다.\n",
    "# 예시로 scaled_data와 동일한 컬럼을 사용했다고 가정하고, 주요 수치형 변수 5개를 사용합니다.\n",
    "\n",
    "# 주요 수치형 변수 5개를 사용하여 결측치가 없는 인덱스를 valid_idx로 지정\n",
    "main_numeric_cols = clustered_df.select_dtypes(include=[np.number]).columns[:5]\n",
    "valid_idx = df.dropna(subset=main_numeric_cols).index\n",
    "\n",
    "print(\"자동으로 추정한 valid_idx (결측치 없는 행의 인덱스, 주요 변수 5개 기준):\")\n",
    "print(valid_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
